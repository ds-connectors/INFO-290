{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Info-290] Commercial Uses of Data\n",
    "\n",
    "## Prompt\n",
    "\n",
    "### Background\n",
    "Earlier this year, Instacart publicly released an anonymized dataset consisting of over 3 million Instacart orders with information from what was purchased and by whom (user ids) and when in the day and week purchases were made. Many retailers, including grocery stores, sell data to data brokers in order to better profile consumers. Often these purchases are linked to credit and debit cards that reveal identity. For more information, here are links [on data brokers](https://www.propublica.org/getinvolved/item/discussion-how-do-data-brokers-impact-you), [on data purchashing firms](http://www.npr.org/sections/alltechconsidered/2016/07/11/485571291/firms-are-buying-sharing-your-online-info-what-can-you-do-about-it), and [Acxiom](http://www.nytimes.com/2012/06/17/technology/acxiom-the-quiet-giant-of-consumer-database-marketing.html?pagewanted=all&_r=0&mtrref=undefined&mtrref=www.nytimes.com&mtrref=www.nytimes.com), a huge database marketer. \n",
    "\n",
    "\n",
    "### Assignment\n",
    "**Using Instacart’s data, try to profile consumers and specific groups within the dataset. For a couple of options, you could try to find a particular demographic, such as millennials, or a group a health insurance company might deem as high-risk.** Included is example analysis code that starts off by pinpointing users who have ordered any kind of potato chips in more than 50% of their orders. \n",
    "\n",
    "You're free to use whatever tools you're comfortable with. [`pandas`](https://pandas.pydata.org/pandas-docs/stable/tutorials.html) is a great library intended for fast data analysis and manipulation of large volumes; however, in this notebook, the included example of data analysis uses Berkeley's [`datascience`](http://data8.org/datascience/) module. \n",
    "\n",
    "To help clarify the content of the data, the Instacart data dictionary can be found [here](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b).\n",
    "\n",
    "\n",
    "### More Details\n",
    "The CSVs within `instacart_data` folder can be opened with a `table.read_table` method. Examples on how to do so are below.  \n",
    "\n",
    "Here is a brief description of some elements of the more confusing (and larger!) CSVs:\n",
    "\n",
    "`orders_subset` - Each row represents one order or trip to the grocery store. `order_number` refers to whether the order was the user’s first or fifteenth. `order_dow` refers to the day of week the order was placed with Saturday as 0 and Sunday as 1. This CSV contains a subset of the original data. \n",
    "\n",
    "`order_products__prior_subset` - Each row represents one product in an order. `add_to_cart_order` refers to the order in which the product was added to the cart. \n",
    "\n",
    "On data integrity, `order_products__prior_subset` holds the data of the subset of users found in `orders_subset`. `orders_subset` has unaltered data for 10% of the unique users found in the original `orders` CSV file. Original data can be downloaded [here](https://www.instacart.com/datasets/grocery-shopping-2017). \n",
    "\n",
    "### Caveat\n",
    "When analyzing the data, especially with a large dataset, be sure to *filter* as much as possible the individual dataframes and then join as needed. In addition, when checking out what each CSV looks like, it’s recommended to use the **`show`** method, rather than loading the entire table — this might crash your notebook (e.g. `table.show(5)`). Note to run terminal commands such as *head* in Jupyter notebook, attach an exclamation point as a prefix to the command (e.g. `!head file.csv`)\n",
    "\n",
    "### To help get you going..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the packages that we'll need for \n",
    "# our most basic functionality\n",
    "from datascience import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Import other libraries you would like to use below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will use `head` to show the first couple of lines of `products.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head instacart_data/products.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read in some of the csv's and store them as `Table` objects from the `datascience` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to open and read in some data files within instacart_data\n",
    "orders = Table().read_table('instacart_data/orders_subset.csv')\n",
    "orders_products = Table().read_table('instacart_data/order_products__prior_subset.csv')\n",
    "products = Table().read_table('instacart_data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a peek at the data stored in the table, we can use the `.show(n)` method on the table, where `n` is the number of rows that you want to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a small look into the first four rows of products -- highly recommended to use .show for large tables \n",
    "products.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysis Example\n",
    "*If you're comfortable with data analysis and Python, feel free to skip this section and get right to analyzing!*\n",
    "\n",
    "To start with, the example seeks to find the group of Instacart users who've bought potato chips consistently. In this particular context, consistently is defined as more than 50% of a user's orders have potato chips in the cart. Using this potato-chip loving crowd, the example will then try to discover more interesting characteristics shared amongst the crowd in order to further profile and target the group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering products to just show products that fit into the category of snacks \n",
    "snacks = products.where('department_id', 19) # Why 19? How did I know that snacks are located in department 19? \n",
    "snacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In addition to orders, orders_products, and products, you have access to two other datasets -- aisles and departments -- located in the folder named instacart_data. \n",
    "To open those datasets, recall how we read products into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following method filters the products table for products with names with specific phrases in them. \n",
    "To use the method, call the method with a case-insensitive string such as 'potato chips' and a table that contains \n",
    "at least the product_name column. The table could be products or another table filtered from products.\n",
    "\n",
    "The method returns a table that shows products with the phrase in its name. If the table is empty, then perhaps\n",
    "the phrase given was too specific. Consider trying the method again with a more general phrase. \n",
    "\n",
    "Examples of using the method:\n",
    "\n",
    "apple_sauce = find_products_by_phrase('apple sauce', products)\n",
    "toilet_paper = find_products_by_phrase('toilet paper', products)\n",
    "\"\"\"\n",
    "\n",
    "def find_products_by_phrase(phrase, table):\n",
    "    if type(phrase) != str:\n",
    "        print(\"Make sure that the phrase has either single or double quotes around it!\")\n",
    "    if 'product_name' not in table.labels:\n",
    "        print(\"Make sure that the table has a column exactly named product_name!\")\n",
    "    return table.where('product_name', lambda x: True if x.lower().find(phrase) != -1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potato_chips = find_products_by_phrase(\"potato chips\", snacks)\n",
    "potato_chips.show(5) # Delicious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have 196 potato chips products, we're going to take a look at the users who have ordered them.\n",
    "There are a couple of questions we need to answer before we can get to what we want. \n",
    "First question: How are we going to link what we found in `potato_chips` to the other tables? \n",
    "Second question: Which of the other tables should we be looking at? Which table first? \n",
    "\n",
    "We're going to answer the second question before the first. Because we want to have a specific group of users based on the content of their orders, we need to have a connection between orders (specifically products in each order) and users. Of the two tables that have information about orders, let's look at the column names to figure out exactly what type of information each has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the `potato_chips` table has `product_id` in common with the `orders_products` table. Also, the `orders_products` table shares `order_id` with the `orders` table. \n",
    "\n",
    "To circle back to the two questions: For the second question, we're going to look at the `orders_products` and `orders` tables in that order. For the first question, we're going to find the relevant `order_id`s in `orders_products` using the `product_id`s in table `potato_chips` and then filter `orders` to only contain those relevant `order_id`s. Let's do it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this long line of code, using select potato_chips is made a smaller table with only the column product_id; \n",
    "similarly, orders_products is made into a table with only two columns, order_id and product_id. \n",
    "Cutting down tables (temporarily) to only contain necessary information and thenjoining decreases the \n",
    "amount of time it takes to perform the join. \n",
    "\n",
    "orders_products_pchips holds two columns both of which are tied to the potato chips we found in our potato_chips table.\n",
    "The first column product_id refers to a specific kind of potato chip product. The second column order_id refers \n",
    "to the specific order a user placed one day. \n",
    "\n",
    "Note: This cell will take approximately 30 seconds to run. \n",
    "\"\"\" \n",
    "\n",
    "orders_products_pchips = orders_products.select(['order_id', 'product_id'])\\\n",
    "                                        .join('product_id', potato_chips.select('product_id'))\n",
    "orders_products_pchips.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because eval_set and days_since_prior_order aren't of interest to me, those two columns were dropped from orders to \n",
    "make the table smaller upon execution of join. What results is a table arbitrarily named pchips_orders_users that \n",
    "connects users to their orders containing potato chips. \n",
    "\"\"\"\n",
    "\n",
    "pchips_orders_users = orders_products_pchips.join('order_id', orders.drop(['eval_set', 'days_since_prior_order']))\n",
    "pchips_orders_users.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we want to filter pchips_orders_users to only contain the users who ordered some kind of potato chips at least\n",
    "in 50% of their orders that exist in our data set. \n",
    "\n",
    "To get a group of users who fit the above criterion, we group pchips_orders_users to obtain the count or number of \n",
    "orders by user containing potato chips. Then using group and join between orders and itself to find the max order \n",
    "number or total number of orders placed by user. We join both of these tables to get the desired user ids. \n",
    "\"\"\"\n",
    "\n",
    "pchips_users = pchips_orders_users.group('user_id').relabel('count', 'pchip order count')\\\n",
    "                                .join('user_id', orders.select(['user_id', 'order_number']).group('user_id', max))\n",
    "pchips_users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add a column, pchip_freq_buyer, to the new pchips_users table which holds True if that user bought\n",
    "# potato chips in more than half of his/her/their orders. \n",
    "\n",
    "pchips_users = pchips_users.with_column('pchip_freq_buyer', \n",
    "                            pchips_users.apply(lambda count, total: True if count/total > 0.5 else False, \n",
    "                                                                   ['pchip order count', 'order_number max']))\n",
    "pchips_users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", pchips_users.where('pchip_freq_buyer', True).num_rows, \n",
    "                                                          \"users who appear to be frequent buyers of potato chips!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering pchips_orders_users to only contain users in pchips_users for which pchip_freq_buyer is True\n",
    "\n",
    "pchips_freq_buyers = pchips_orders_users.join('user_id', \n",
    "                                              pchips_users.where('pchip_freq_buyer', True).select('user_id'))\n",
    "pchips_freq_buyers.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps\n",
    "We're at the point where we have a table, pchips_freq_buyers, with which we can find all sorts of interesting characteristics about this population. At this point, hopefully you feel comfortable conducting your own analyses. If not, the following code will finish off, for now, this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: What's the most popular kind of potato chips? \n",
    "popular_pchip_row = pchips_freq_buyers.group('product_id').sort('count', descending=True).row(0)\n",
    "popular_pchip_id = popular_pchip_row[0]\n",
    "print(\"Most popular kind among this user group is:\", \n",
    "      products.where('product_id', popular_pchip_id).column('product_name')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some visualizations of the data findings: \n",
    "![alt text](images/example_analysis_1.png)\n",
    "#### Compare the above with this table of bestsellers based on the entire original dataset: \n",
    "![alt text](images/compare_1_a.png)\n",
    "\n",
    "![alt text](images/example_analysis_2.png)\n",
    "![alt text](images/example_analysis_3.png)\n",
    "#### Compare the above with these bar charts based on data the entire orders_subset: \n",
    "![alt text](images/compare_2.png)\n",
    "![alt text](images/compare_3.png)\n",
    "\n",
    "*The remaining code of the example is all about the visualizations shown here. Feel free to reference the code if you would like to build a horizontal bar chart or histogram.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pchips_freq_buyers.column('order_dow'), color='green')\n",
    "plt.title('DoW for Orders Containing Potato Chips by Frequent Buyers of Potato Chips', y=1.08)\n",
    "plt.xlabel('DoW (0=Saturday, 1=Sunday)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pchips_freq_buyers.column('order_hour_of_day'), color='green')\n",
    "plt.title('Hour of Day for Orders Containing Potato Chips by Frequent Buyers of Potato Chips', y=1.08)\n",
    "plt.xlabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: What other products are ordered frequently by this specific group of people? (this cell will take a while)\n",
    "\n",
    "freq_pchip_buyers_id = pchips_users.where('pchip_freq_buyer', True).select('user_id') \n",
    "\n",
    "# Getting the order ids \n",
    "freq_pchip_buyers_orders = orders.select(['user_id', 'order_id']).join('user_id', freq_pchip_buyers_id)\n",
    "\n",
    "# Linking the order ids to product ids \n",
    "freq_pchip_buyers_productids = orders_products.select([\"order_id\", \"product_id\"])\\\n",
    "                                              .join('order_id', freq_pchip_buyers_orders)\n",
    "    \n",
    "# Linking product ids to product names\n",
    "freq_pchip_buyers_products = freq_pchip_buyers_productids.select(['product_id'])\\\n",
    "                                                         .join('product_id', \n",
    "                                                               products.select(['product_id', 'product_name']))\n",
    "     \n",
    "# Getting the top 10 products most commonly purchased by this group of potato chip frequent buyers\n",
    "# Note that the 'count' column refers to number of orders\n",
    "freq_pchip_buyers_products = freq_pchip_buyers_products.group('product_name')\\\n",
    "                                                       .sort('count', descending=True)\\\n",
    "                                                       .take(np.arange(10))\n",
    "freq_pchip_buyers_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ypos = np.arange(10)\n",
    "ax.barh(ypos, freq_pchip_buyers_products.column('count'), color='green')\n",
    "ax.set_yticklabels(freq_pchip_buyers_products.column('product_name'))\n",
    "ax.set_yticks(ypos)\n",
    "ax.invert_yaxis() \n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Bestsellers Amongst the Potato-Chips Frequent Buyers', y=1.08)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ds100]",
   "language": "python",
   "name": "Python [ds100]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
